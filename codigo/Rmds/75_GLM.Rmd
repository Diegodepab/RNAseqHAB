## GLM: Generalised linear model

[START EXPANDIBLE]: #
`r EXPAND_bx` Expand to read about <b>GLMs and RNA-seq</b></summary>

Los datos de la RNA-seq podemos ajustarlos a un [GLM] porque en este modelo, un cambio constante en un predictor conduce a un cambio constante en la variable de respuesta. Es decir, que exite una [**correlación lineal**](https://www.r-bloggers.com/2021/10/simple-linear-regression-in-r/) entre las variables analizadas, y que después del ajuste **el ruido  tenga una distribución normal**. Además, también debe cumplirse que haya **homoescedascidad** (igual (_homo_) dispersion (_skedasis_)) entre ellas, esto es, que el ruido (variabilidad) no dependa del valor (con los genes será el nivel de expresión), sino que **sea igual a valores bajos y a valores altos**. En la mayoría de los análisis estadísticos, la variabilidad de la dispersión (**heteroescedascidad**) no es preocupante, pero sí lo es en los análisis de regresión, porque puede arruinar los resultados. Estas situaciones se ilustran muy bien en la siguiente figura:

![Figura ilustrativa de heteroescedascidad y homoescedascidad](https://miro.medium.com/max/1150/1*zME3uz7yeCMGCIXngn5Ygw.png)

Para más información tienes [este enlace](https://online.stat.psu.edu/stat504/lesson/6/6.1) y [este otro](https://towardsdatascience.com/generalized-linear-models-9ec4dfe3dc3f).

Por desgracia, en la RNA-seq los datos varían en función de la intensidad (recuento): los que tienen recuentos bajos tienden a ser muy variables (tienen más ruido, son más propensos a una correlación errónea), mientras que los que tienen recuentos altísimos varían mucho menos (se subestima la variablidad). De hecho, los datos en bruto muestran un aumento de la varianza a medida que se incrementa el valor del recuento, y cuando se usa el logaritmo del recuento se observa una caída en la varianza de la media.

</details> 
[END EXPANDIBLE]: #

Antes de hacer el [GLM] con los datos de RNA-seq, tenemos que estar seguros de que nuestros datos son homoescedásticos.

### Heteroescedascidad {-}

Hay que corregir la heteroescedascidad que suelen contener los datos de RNA-seq, sobre todo **cuando el tamaño de las librerías es desigual**. Para ello usaremos la función `voom()` de la librería [limma] con la que se crea un objeto `v` de clase `EList` en el que:

* `v$targets` equivale a `x$samples`
* `v$E` contiene los valores de expresión, análogo a `x$counts`, pero en una escala diferente
* `v$weights` es la matriz de ponderación
* `v$design` almacena la matriz del diseño (`design`)
* `v$genes` es un data frame  equivalente a `x$genes` (si existe)

Como se indica en [@Law2014tt], **`voom()` es más potente que otros ajustes basados en `limma-trend`** (en el que se fija `trend = TRUE` en las funciones `eBayes()` o `treat()`) o [QLF]. Así pues:

1. No debemos cambiar el valor de `trend` cuando usamos `voom()`;
2. No usaremos `voom()` con ningún dato que haya sido normalizado por el tamaño de la librería, como las [CPM], TPM (**t**ranscritos **p**or **m**illón) o las RPKM (**r**ecuento **p**or **k**ilobase y **m**illón de lecturas).

Con `voom()` no solo eliminamos la heteroescedascidad, sino que también podemos representarla antes del ajuste si a dicha función le añadimos el parámetro `plot = TRUE`. Esto implica retrasar bastante la ejecución del script, por lo que te recomiendo que para futuros usos ponga el parámetro `doPlot` en `FALSE`.

```{r corrigeHeteroesc, fig.width=5, fig.height=5, out.width=c('33%', '33%', '33%'), fig.show='hold'}
doPlot <- TRUE
v <- voom(x, design, plot = doPlot)
title(sub = RAW_TXT)
v.filt <- voom(x.filt, design, plot = doPlot)
title(sub = FILT_TXT)
v.filt.norm <- voom(x.filt.norm, design, plot = doPlot)
title(sub = NORM_TXT)
```

> **IMPORTANTE**: Observa que los datos eliminados por la filtración son los que más heteroescedascidad presentan, por lo que es necesario quitarlos siempre.


### Save corrected data {-}

Vamos a guardar la corrección de la heteroescedascidad para los datos filtrados y normalizados. Los otros tipos de datos se mantienen para la comparativa posterior, pero no porque sean útiles.

```{r saveCorrected}
fileName <- SaveTSV(v.filt.norm$E, "normHomoscedCPM-")
message("**Filtered, normalised and variance corrected** expression data were saved in\n", fileName)
```



### Procedimiento bayesiano {-}

La función de R `glm()` es la que se encarga de realizar el ajuste a un [GLM] sobre la variable en la que se ha corregido la heteroescedacidad. 
En [limma], se ha adaptado este ajuste al objeto de expresión, con lo que tendremosn las siguientes funciones:

* `lmFit()` para ajustar el GLM para cada gen entre las muestras;
* `contrasts.fit()` para calcular el coeficiente de la estimación y el error estándar para un conjunto de contrastes;
* `eBayes()`  para un ajuste moderado de la _t_ de Student para la expresión diferencial gracias a una moderación empírica bayesiana del error estándar que intenta compensar las pocas réplicas con las que solemos contar. Recuerda lo visto en el apartado [Dispersión en los datos][#binomialNegative]. Recuerda que si no necesitas eliminar la heteroescedascidad con `voom()`, fijar `trend = TRUE` (método conocido como limma-trend) mejora los resultados.

Vamos a hacer los ajustes con los datos brutos, los filtrados, y los normalizados y filtrados, todos ellos sin heteroescedascidad. 

En este ajuste, podemos lanzar a la vez todos los contrastes que aparezcan en la matriz `contr.matrix`, aunque solo el primero lo podremos comparar con los resultados del test exacto y el [QLF].

```{r GLM-eBayes}
# RAW data
v.fit <- lmFit(v, design)
v.fit <- contrasts.fit(v.fit, contrasts = contr.matrix)
v.fit.eB <- eBayes(v.fit)

# for filtered data
v.filt.fit <- lmFit(v.filt, design)
v.filt.fit <- contrasts.fit(v.filt.fit, contrasts = contr.matrix)
v.filt.fit.eB <- eBayes(v.filt.fit)

# for filtered and normalised data
v.filt.norm.fit <- lmFit(v.filt.norm, design)
v.filt.norm.fit <- contrasts.fit(v.filt.norm.fit, contrasts = contr.matrix)
v.filt.norm.fit.eB <- eBayes(v.filt.norm.fit)
```

Vamos a ver el aspecto de los puntos para comprobar que el ajuste ya no contiene heteroescedacidad.

```{r plotSA, fig.width=8, fig.height=3}
par(mfrow = c(1, 3))
plotSA(v.fit.eB, main = "Raw Mean−variance, treat")
title(sub = RAW_TXT)
plotSA(v.filt.fit.eB, main= "treat() after filtering")
title(sub = FILT_TXT)
plotSA(v.filt.norm.fit.eB, main = "Final model")
title(sub = NORM_TXT)
```

Compáralo con los datos de los BCV y las _mean-variance trends_ antes del ajuste con [plotBCV][Visualización de la dispersión] y [Heteroescedascidad][Heteroescedascidad].


### Procedimiento con `treat()` {-}

El procedimiento bayesiano anterior no realiza ningún ajuste especial sobre los valores de `P` y `FC` definidos para los cortes. Pero existe cada vez más preocupación por el uso incorrecto de la _P_ y los intervalos de confianza.

[START EXPANDIBLE]: #
`r EXPAND_bx` Expand to read about <b>the usual misinterpretation of <i>P</i>-values</b></summary>

Statistical significance offers the benefit of simplicity and clarity on the one hand. 
But the size of the effect is not indicated by the statistical significance.
Those and others drawbacks of the _P_-value led some to advocate for more sophisticated models (such as the Bayesian approach mentioned above). One of those agents claiming the proper use and interpretation of the _P_-value is The American Statistical Association (ASA), which highlights that **scientific conclusions should not be based only on whether a _P_-value passes a specific threshold since, by itself, a _P_-value does not provide a good measure of evidence regarding a model or hypothesis**. 

Since associating statistically significant findings with $P < 0.05$ (as arbitrarily introduced by Ronald Fisher in 1925) results in a high rate of false positives, the ASA also recommends that **declarations realted to _statistical significance_ should be abandoned** since statistical significance was never meant to imply scientific importance [@Wasserstein2019] and it has promoted conscious or unconscious bad practices in research [@Mayo2022aa]. The situation is so worrying that some authors claim that most published research findings are false [@Ioannidis2005ud] or highly biased [@Altman2017mv]. 

**Common misinterpretation of statistical significance**:

The following limitations have been described in detail in [@Amrhein2017aa,@Amrhein2019,@Montero2023aa].

* **$P$-values**: they ~~do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone~~, but the probability of the test statistic assuming the null hypothesis. In fact, _P-values depend on your data and are not reliable_.
* **Confidence intervals**: many researchers incorrectly believe that ~~the confidence interval from an isolated experiment has a 95% chance of containing the true value, or intervals that will contain the parameter with a given probability~~. They simply are a frequency description of samples from a population in large-scale resampling of this population. Be aware that _many researchers wrongly interpret confidence intervals as Bayesian credible intervals_.
* **Statistical significance**: it was introduced as a tool to suggest interesting results and perform further confirmatory research and not as ~~a true-difference/no-difference decision boundary~~. Subsequently, the variables selected as being truly changed are considered to be scientifically significant and merit more research. _The absence of statistical significance does not indicate an absence of an effect_. And the _presence of statistical significance does not mean scientific significance_.
* **False discovery rate (FDR)** is usually set to control the ratio of false positives when multiple hypothesis tests are performed, such as in omics studies. But this approach requires independent variables, which is not the case, since many genes/proteins are acting on other genes/proteins, and _FDR test statistic cannot be used since it would drive and potentially bias the extraction of the biological information contained in the omic data_.


In fact, in omics sciences, the frequent misuse of _P_-values is limiting the generation of robust scientific knowledge [@Montero2023aa,@Amrhein2019]:

* biological inferences are derived only from biomolecules with statistically significant changes;
* only the biomolecules with statistically significant changes are selectively reported (biasing the published results); and
* asterisks or inequalities ($P < 0.05, P < 0.001$) are reported instead of the obtained _P_-values. 

To circumvent these misinterpretations:

* You should never conclude that there is _no difference_ or _no association_ just because $P < 0.05$ because a confidence interval includes zero or your reference in the H0 hypothesis. 
* You should never conclude that two studies conflict because one had a statistically significant result and the other did not.
* _P_-values should be given with a precise value ($P = 0.021$), without adornments such as stars or asterisks, and not as binary inequalities (~~$P < 0.05$~~)
* You must focus on the parameter that measures your biological effect (for example, the fold-change) and not the _P_-values or the confidence intervals.

![Beware false conclusions](https://media.nature.com/lw800/magazine-assets/d41586-019-00857-9/d41586-019-00857-9_16551622.jpg)




**Possible solutions**: 

It is obvious that statistics naturally vary from study to study and can lead to large disparities in _P_-values, far beyond falling just to either side of the 0.05 threshold (see the image above). Therefore, **we must consider uncertainity** and, for example, re-think _confidence intervals_ as **compatibility intervals** to transmit the idea that [all the values between the interval's limits are reasonably compatible with the data](https://github.com/matloff/regtools/blob/master/inst/NoPVals.md). Hence, because the interval gives the values most compatible with the data, it doesn't mean values outside it are incompatible: they are just less compatible. Therefore, **compatibility intervals are more informative and more intuitive**. 


Second, it is not a question of abandoning the use of statistical significance since it would favour unjustified claims and mislead science, favouring non-ethical practices [@Wasserstein2019]. However, a better use of hypothesis tests and _P_-values by researchers in the new context of _compatibility intervals_ is necessary:

1. Change to lower _P_-values (for example $P < 0.005$) to reduce the false positives and improve the reproducibility of research [@Benjamin2018sj]. It is simple to implement but would produce an enormeous amount of false negative results that favours the new perception that [low _P_ values does imply more significance or more importance](https://github.com/matloff/regtools/blob/master/inst/NoPVals.md). Additionally, more stringent _P_values will require larger samples (that may not be feasible).
2. Avoid _dichotomisation_ (significant vs. non-significant) as much as possible [@Amrhein2019] and learn to deal with uncertainty.
3. Contrary as is commonly thought, ~~do not select genes by the _P_-value and then use the fold-change for priorisation~~, but select them by the fold-change (that focuses on the size of effect you are analysing) and then priorise by the _P_-value only if some filtering is required [@Mayo2022aa,@Montero2023aa]. Then, repeat the experiment to confirm your results, even though you obtain different (but compatible) fold-changes and _P_-values.
4. Add a Bayesian perspective to the analysis to produce _credible intervals_ corresponding to the distributions of the plausibility of the values of the parameter. Its main drawback is that when the number of samples is low, result may be hihgly biased.


However, it is recognised that _P_-values and statistical significance are a prerequisite to proof that the outcomes are not random. But for understanding the effect magnitude, at least a second parameter should be considered, such as the fold-change in genes, proteins or metabolites: 

1. _P_-values must be integrated with secondary results to arrive at valid conclusions [@Lu2015wd]. In the case of RNA-seq, the secondary result is the **expression fold-change**, that reflects the change magnitude.
2. Researchers should seek to analyse data in multiple ways (including statistics) to see whether different analyses converge on the same answer [@Nature2019].
3. Avoid selecting genes by statistical significance relying on solid cutoffs. Instead, relax cutoffs and interpret your outcomes in the context of previous knowledge and the known relationships among genes and proteins [@Betensky2019].

</details> 
[END EXPANDIBLE]: #



Como todavía no sabemos hacer una estadística en la que _P_ varíe en función de la variabilidad de los datos, la aproximáción más válida que se ha hecho es con la función `treat()` (en lugar de `eBayes()`) que incrementa el rigor con respecto a los valores de `P` y `FC` definidos para los cortes [@McCarthy2009oo]. De ahí que convenga tener muy presente la siguiente _nota del autor_: 

> The logFC threshold is usually chosen relatively small, because significantly DEGs must all have fold changes substantially greater than the testing threshold. Typical values for logFC includes FC = 1.1, FC = 1.2 or FC = 1.5.  Therefore, **FC = 2 is considered high**.

Así pues, `treat()` parte del umbral de `FC` inicial (que no debe ser muy restrictivo) para reajustar el corte por `FC` en función de los recuentos y de cuán fiablemente están por encima del `logFC` y la `P` definidas [@Law2016yj]. De esta forma, `treat()` da preferencia a los `FC` más altos con lo que **prioriza los genes con mayor relevancia biológica**, por lo que el `FC` ya no es un mero umbral mínimo que hay que supear, sino que debemos considerarlo _el cambio de expresión mínimo que ha de tener un gen para que quizá nos interesemos por él_ en vez del clásico ~~el cambio de expresión a partir del cual nos interesaremos en un gen~~.

Las ventajas de usar la estrategia combinada de `limma + voom` y luego `treat()` son las siguientes:

1. Produce resultados más exactos (con más sentido biológico) [@Law2014tt; @Li2022cf];
2. Soporta mejor los desequilibrios de tamaño de las librerías [@Law2014tt];
3. Maneja mejor que otros métodos paramétricos los valores atípicos [@Soneson2013];
4. Exagera los errores experimentales cuando los datos se han normalizado con métodos menos apropiados (como RPKM, CPM o TMP) en vez de [TMM].


Calculemos los nuevos valores de expresión diferencial a partir de las variables `xxx.fit` calculadas antes, que incluye todos las comparaciones guardadas en la matriz `contr.matrix`. Ahora, en lugar de terminalas en `xxx.fit.eB` (obtenidas con `eBayes()`), las terminaremos en `xxx.fit.treat`:

```{r GLM-treat}
# RAW data
v.fit.treat <- treat(v.fit, lfc = logFC)
# for filtered data
v.filt.fit.treat <- treat(v.filt.fit, lfc = logFC)
# for filtered and normalised data
v.filt.norm.fit.treat <- treat(v.filt.norm.fit, lfc = logFC)

# remove needless variables
rm(v.fit, v.filt.fit, v.filt.norm.fit)
```


### MD plots (GLM) {-}

Volvemos a usar los umbrales de `P`y `FC` para marcar en <span style="color:blue">**azul**</span> los genes <span style="color:blue">reprimidos</span> y en <span style="color:red">**rojo**</span> los genes <span style="color:red">activados</span>.

```{r bayes-treat}
# Quatifly genes as 1 (up-regulated in red), -1 (down-regulated in blue) or 0 (non significant)
# raw eBayes
eB.status.p.fc <- decideTests(v.fit.eB, p.value = P, lfc = logFC)
# filtered eBayes
eB.filt.status.p.fc <- decideTests(v.filt.fit.eB, p.value = P, lfc = logFC)
# filtered + normalised eBayes
eB.filt.norm.status.p.fc <- decideTests(v.filt.norm.fit.eB, p.value = P, lfc = logFC)

# raw treat
dt.raw <- decideTests(v.fit.treat, p.value = P, lfc = logFC)
# filtered treat
dt.filt <- decideTests(v.filt.fit.treat, p.value = P, lfc = logFC)
# normalised treat
dt.norm <- decideTests(v.filt.norm.fit.treat, p.value = P, lfc = logFC)
```

Representemos los valores con **ajuste bayesiano**, pero recuerda que en los objetos `xxx.eB` están guardados los resultados de todos los contrastes. Vamos a inspeccionar solo el primero (`column = 1`) para poderlo comparar con lo anterior.:

```{r MDplotx3, fig.width=4.5, fig.height=5, out.width=c('33%', '33%', '33%'), fig.show='hold'}
EB <- "eBayes()"
plotMD(v.fit.eB, column = 1,
       status = eB.status.p.fc[, 1], 
       hl.cex = 0.5,
       main = paste(EB, RAW_TXT, ":", colnames(eB.status.p.fc[, 1])))
# mark logFC cutoffs
abline(h = c(-logFC, logFC), col = "magenta")

plotMD(v.filt.fit.eB, column = 1,
       status = eB.filt.status.p.fc[, 1], 
       hl.cex = 0.5,
       main = paste(EB,FILT_TXT, ":", colnames(eB.filt.status.p.fc[, 1])))
abline(h = c(-logFC, logFC), col = "magenta")

plotMD(v.filt.norm.fit.eB, column = 1,
       status = eB.filt.norm.status.p.fc[, 1], 
       hl.cex=0.5,
       main = paste(EB, NORM_TXT, ":", colnames(eB.filt.norm.status.p.fc[, 1])))
abline(h = c(-logFC, logFC), col = "magenta")
```

> **IMPORTANTE**: Se observa claramente que en los datos brutos se han logrado dejar fuera una serie de genes de poca expresión que no se ajustan a un modelo lineal

> **IMPORTANTE**: Salvo cuando los datos son de muy mala calidad (los brutos/_raw_), el corte para la expresión diferencial está sobre el valor de `FC` definido en la configuración.


Veamos la diferencia de las gráficas anteriores con los resultados obtenidos **con `treat()`** en, incluidos los datos de QLF.

```{r newMDplotx3, fig.width=4.5, fig.height=5, out.width=c('33%', '33%', '33%'), fig.show='hold'}
TR <- "treat()"
plotMD(v.fit.treat, column = 1, 
       status = dt.raw[ ,1], 
       main = paste(TR, RAW_TXT, ":", colnames(v.fit.treat)[1]), 
	   xlim = c(-8, 13), ylim = c(-10, 10),
       hl.cex=0.5)
abline(h = c(-logFC, logFC), col = "magenta")

plotMD(v.filt.fit.treat, column = 1, 
       status = dt.filt[ ,1], 
       main = paste(TR, FILT_TXT, ":", colnames(v.filt.fit.treat)[1]), 
       xlim = c(-8, 13), ylim = c(-10, 10), 
       hl.cex=0.5)
abline(h = c(-logFC, logFC), col = "magenta")

plotMD(v.filt.norm.fit.treat, column = 1, 
       status = dt.norm[ ,1], 
       main = paste(TR, NORM_TXT, ":", colnames(v.filt.norm.fit.treat)[1]), 
       xlim = c(-8, 13), ylim = c(-10, 10),
       hl.cex=0.5)
abline(h = c(-logFC, logFC), col = "magenta")
```

> **IMPORTANTE**: En todos los casos, el corte para la expresión diferencial está por encima del valor de `FC` definido en la configuración. Cuanto peor es la calidad de los datos, mayor es el `FC` que debe tener el gen para ser considerado con expresión diferencial **relevante**.

